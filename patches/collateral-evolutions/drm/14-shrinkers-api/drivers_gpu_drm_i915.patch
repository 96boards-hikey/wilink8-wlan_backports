diff --git a/drivers/gpu/drm/i915/i915_dma.c b/drivers/gpu/drm/i915/i915_dma.c
index 64cad3f..008009f 100644
diff --git a/drivers/gpu/drm/i915/i915_gem.c b/drivers/gpu/drm/i915/i915_gem.c
index 29eff1d..7fb1804 100644
--- a/drivers/gpu/drm/i915/i915_dma.c
+++ b/drivers/gpu/drm/i915/i915_dma.c
@@ -1654,7 +1654,11 @@ int i915_driver_load(struct drm_device *
 	return 0;
 
 out_gem_unload:
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,11,0))
 	if (dev_priv->mm.inactive_shrinker.scan_objects)
+#else
+	if (dev_priv->mm.inactive_shrinker.shrink)
+#endif
 		unregister_shrinker(&dev_priv->mm.inactive_shrinker);
 
 	if (dev->pdev->msi_enabled)
@@ -1685,7 +1689,11 @@ int i915_driver_unload(struct drm_device
 
 	i915_teardown_sysfs(dev);
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,11,0))
 	if (dev_priv->mm.inactive_shrinker.scan_objects)
+#else
+	if (dev_priv->mm.inactive_shrinker.shrink)
+#endif
 		unregister_shrinker(&dev_priv->mm.inactive_shrinker);
 
 	mutex_lock(&dev->struct_mutex);
--- a/drivers/gpu/drm/i915/i915_gem.c
+++ b/drivers/gpu/drm/i915/i915_gem.c
@@ -53,10 +53,15 @@ static void i915_gem_object_update_fence
 					 struct drm_i915_fence_reg *fence,
 					 bool enable);
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,11,0))
 static long i915_gem_inactive_count(struct shrinker *shrinker,
 				    struct shrink_control *sc);
 static long i915_gem_inactive_scan(struct shrinker *shrinker,
 				   struct shrink_control *sc);
+#else
+static int i915_gem_inactive_shrink(struct shrinker *shrinker,
+				    struct shrink_control *sc);
+#endif
 static long i915_gem_purge(struct drm_i915_private *dev_priv, long target);
 static long i915_gem_shrink_all(struct drm_i915_private *dev_priv);
 static void i915_gem_object_truncate(struct drm_i915_gem_object *obj);
@@ -4277,8 +4282,12 @@ i915_gem_load(struct drm_device *dev)
 
 	dev_priv->mm.interruptible = true;
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,11,0))
 	dev_priv->mm.inactive_shrinker.scan_objects = i915_gem_inactive_scan;
 	dev_priv->mm.inactive_shrinker.count_objects = i915_gem_inactive_count;
+#else
+	dev_priv->mm.inactive_shrinker.shrink = i915_gem_inactive_shrink;
+#endif
 	dev_priv->mm.inactive_shrinker.seeks = DEFAULT_SEEKS;
 	register_shrinker(&dev_priv->mm.inactive_shrinker);
 }
@@ -4501,8 +4510,13 @@ static bool mutex_is_locked_by(struct mu
 #endif
 }
 
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,11,0))
 static long
 i915_gem_inactive_count(struct shrinker *shrinker, struct shrink_control *sc)
+#else
+static int
+i915_gem_inactive_shrink(struct shrinker *shrinker, struct shrink_control *sc)
+#endif
 {
 	struct drm_i915_private *dev_priv =
 		container_of(shrinker,
@@ -4511,7 +4525,12 @@ i915_gem_inactive_count(struct shrinker
 	struct drm_device *dev = dev_priv->dev;
 	struct drm_i915_gem_object *obj;
 	bool unlock = true;
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,11,0))
 	long cnt;
+#else
+	int nr_to_scan = sc->nr_to_scan;
+	int cnt;
+#endif
 
 	if (!mutex_trylock(&dev->struct_mutex)) {
 		if (!mutex_is_locked_by(&dev->struct_mutex, current))
@@ -4523,6 +4542,17 @@ i915_gem_inactive_count(struct shrinker
 		unlock = false;
 	}
 
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3,11,0))
+	if (nr_to_scan) {
+		nr_to_scan -= i915_gem_purge(dev_priv, nr_to_scan);
+		if (nr_to_scan > 0)
+			nr_to_scan -= __i915_gem_shrink(dev_priv, nr_to_scan,
+							false);
+		if (nr_to_scan > 0)
+			i915_gem_shrink_all(dev_priv);
+	}
+#endif
+
 	cnt = 0;
 	list_for_each_entry(obj, &dev_priv->mm.unbound_list, global_list)
 		if (obj->pages_pin_count == 0)
@@ -4535,6 +4565,8 @@ i915_gem_inactive_count(struct shrinker
 		mutex_unlock(&dev->struct_mutex);
 	return cnt;
 }
+
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,11,0))
 static long
 i915_gem_inactive_scan(struct shrinker *shrinker, struct shrink_control *sc)
 {
@@ -4568,3 +4600,4 @@ i915_gem_inactive_scan(struct shrinker *
 		mutex_unlock(&dev->struct_mutex);
 	return freed;
 }
+#endif
